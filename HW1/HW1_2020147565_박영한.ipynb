{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification with Amazon Review Data\n",
        "\n",
        "CSI4121 Big Data, Spring 2023\n",
        "\n",
        "Homework 1 - 2020147565 Younghan Park\n",
        "\n",
        "In this notebook, we are going to classify ratings of Amazon reviews on video games.\n",
        "\n",
        "https://nijianmo.github.io/amazon/index.html\n",
        "\n",
        "## Preparing Datas\n",
        "\n",
        "### Loading Datas"
      ],
      "metadata": {
        "id": "bbxSsPxpAvNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "os.chdir('drive/MyDrive/연세대학교 2학년 2학기 (2023-1)/CSI4121 Big Data/Homework 1')"
      ],
      "metadata": {
        "id": "dLmgHp1qGgB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "cC_xGmv9Tor9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import json\n",
        "\n",
        "data = []\n",
        "with gzip.open('Video_Games_5.json.gz') as f:\n",
        "  for l in f:\n",
        "    data.append(json.loads(l.strip()))"
      ],
      "metadata": {
        "id": "j3QhraoROKjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame.from_dict(data)[['overall', 'reviewText']].dropna(subset=['overall', 'reviewText'])\n",
        "\n",
        "df = df[(df['overall'] < 2.5) | (df['overall'] > 3.5)]\n",
        "for index, row in df.iterrows():\n",
        "  if row['overall'] < 2.5:\n",
        "    df.loc[index, 'overall'] = 0\n",
        "  elif row['overall'] > 3.5:\n",
        "    df.loc[index, 'overall'] = 1\n",
        "\n",
        "df = df.head(200000)\n",
        "print(df.head())\n",
        "print('# of Datas:', len(df))"
      ],
      "metadata": {
        "id": "gRXeerUGVUm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Dataset\n",
        "\n",
        "First, we are going to do tokenization, with Penn Treebank Tokenizer(default tokenizer of nltk package).\n",
        "\n",
        "After that, we are going to generate word-to-int mapping."
      ],
      "metadata": {
        "id": "G0WwdVLsZXDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "df['tokenized'] = df['reviewText'].apply(tokenizer.tokenize)"
      ],
      "metadata": {
        "id": "uAcoEGbnxtQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "corpus = []\n",
        "for text in df['tokenized']:\n",
        "  corpus += [word for word in text]\n",
        "count_words = Counter(corpus)\n",
        "sorted_words = count_words.most_common()\n",
        "vocab_to_int = {w: i + 1 for i, (w, c) in enumerate(sorted_words)}"
      ],
      "metadata": {
        "id": "wxBbHUhKZWdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "for text in df['tokenized']:\n",
        "  X.append([vocab_to_int[word] for word in text])\n",
        "\n",
        "df['X'] = X\n",
        "df['len_X'] = [len(_) for _ in df['X']]"
      ],
      "metadata": {
        "id": "muuxnm37cs6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(df['len_X'].describe())\n",
        "\n",
        "df['len_X'].hist(bins = range(min(df['len_X']), max(df['len_X']) + 50, 50))\n",
        "plt.title('Sentence length distribution', size=15)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "CFSZhjYOwRId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['overall'].describe())\n",
        "\n",
        "df['overall'].hist(bins = 5)\n",
        "plt.title('Label distribution', size=15)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "l2jQJ6aft69h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "seq_len = 300\n",
        "features = np.zeros((len(df['X']), seq_len), dtype=int)\n",
        "for i, text in enumerate(df['X']):\n",
        "  if len(text) <= seq_len:\n",
        "    features[i, :len(text)] = text\n",
        "  else:\n",
        "      features[i, :] = text[:seq_len]"
      ],
      "metadata": {
        "id": "SC6ZO___rpMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_category = df['overall'].nunique()\n",
        "onehot_y = pd.get_dummies(df['overall']).to_numpy()"
      ],
      "metadata": {
        "id": "EeNM8LdFSyDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Dataloaders"
      ],
      "metadata": {
        "id": "gA3zETQYz0rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_remain, y_train, y_remain = train_test_split(features, onehot_y, test_size=0.2)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_remain, y_remain, test_size=0.5)"
      ],
      "metadata": {
        "id": "jlvF4_k6t2zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "val_data = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size = 256"
      ],
      "metadata": {
        "id": "vY5QSdFVxlrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "metadata": {
        "id": "w1XDMsDY0lj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "sample_X, sample_y = next(dataiter)\n",
        "print('Sample input X size:', sample_X.size())\n",
        "print('Sample input X:', sample_X)\n",
        "print('Sample label Y size:', sample_y.size())\n",
        "print('Sample label y:', sample_y)"
      ],
      "metadata": {
        "id": "QIAFVsgxzA1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "We are going to use bidirectional LSTM."
      ],
      "metadata": {
        "id": "qcHbro3Uz5BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, use CPU\")"
      ],
      "metadata": {
        "id": "znRE250VzpOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Bi_LSTM(nn.Module):\n",
        "  def __init__(self, output_size, hidden_dim, n_layers, vocab_size, embedding_dim, drop_prob=0.5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.output_size = output_size\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.n_layers = n_layers\n",
        "    self.num_category = num_category\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional=True)\n",
        "\n",
        "    self.fc = nn.Linear(2 * hidden_dim, output_size)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "  \n",
        "  def forward(self, x, hidden):\n",
        "    embeds = self.embedding(x)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    lstm_out = lstm_out[:, -1]\n",
        "\n",
        "    out = self.fc(lstm_out)\n",
        "    out = self.dropout(out)\n",
        "\n",
        "    return out, hidden\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    h0 = torch.zeros((2 * self.n_layers, batch_size, self.hidden_dim)).to(device)\n",
        "    c0 = torch.zeros((2 * self.n_layers, batch_size, self.hidden_dim)).to(device)\n",
        "    return (h0, c0)"
      ],
      "metadata": {
        "id": "YJTphs2CLTVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab_to_int) + 1  # 1 for padding(0)\n",
        "output_size = num_category\n",
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "model = Bi_LSTM(output_size, hidden_dim, n_layers, vocab_size, embedding_dim).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "pMyv19hlPHsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ILedIPXkPdQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.utils.class_weight as class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(df['overall']), y=df['overall'])\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "class_weights"
      ],
      "metadata": {
        "id": "I1ksBPytvgvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "epochs = 20\n",
        "clip = 5"
      ],
      "metadata": {
        "id": "JZnadJzZPhpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(pred, label):\n",
        "  return (torch.argmax(pred, 1) == torch.argmax(label, 1)).int().sum()"
      ],
      "metadata": {
        "id": "UoGwruCjQpvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_history, val_loss_history = [], []\n",
        "train_acc_history, val_acc_history = [], []\n",
        "valid_loss_min = np.Inf"
      ],
      "metadata": {
        "id": "XGQXVhn1Q4UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader.dataset)"
      ],
      "metadata": {
        "id": "HcuAlabOlRsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_losses = []\n",
        "  train_acc = 0\n",
        "  total_train_num = 0\n",
        "  model.train()\n",
        "  h = model.init_hidden(batch_size)\n",
        "\n",
        "  for inputs, labels in train_loader:\n",
        "    h  = tuple([each.data for each in h])\n",
        "\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "    output, h = model(inputs, h)\n",
        "    \n",
        "    loss = criterion(output.float(), labels.float())\n",
        "    loss.backward()\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    train_acc += acc(output, labels)\n",
        "    total_train_num += output.size(0)\n",
        "\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "  val_losses = []\n",
        "  val_acc = 0.0\n",
        "  total_val_num = 0\n",
        "  model.eval()\n",
        "  h_v = model.init_hidden(batch_size)\n",
        "\n",
        "  for inputs_v, labels_v in val_loader:\n",
        "    h_v = tuple([each.data for each in h_v])\n",
        "\n",
        "    inputs_v, labels_v = inputs_v.to(device), labels_v.to(device)\n",
        "\n",
        "    output_v, h_v = model(inputs_v, h_v)\n",
        "\n",
        "    loss_v = criterion(output_v.float(), labels_v.float())\n",
        "    val_losses.append(loss_v.item())\n",
        "\n",
        "    val_acc += acc(output_v, labels_v)\n",
        "    total_val_num += output_v.size(0)\n",
        "  \n",
        "  epoch_train_loss = np.mean(train_losses)\n",
        "  epoch_val_loss = np.mean(val_losses)\n",
        "  epoch_train_acc = train_acc / total_train_num * 100  # deviding by number of batches\n",
        "  epoch_val_acc = val_acc / total_val_num * 100 # deviding by number of batches\n",
        "\n",
        "  train_loss_history.append(epoch_train_loss)\n",
        "  val_loss_history.append(epoch_val_loss)\n",
        "  train_acc_history.append(epoch_train_acc)\n",
        "  val_acc_history.append(epoch_val_acc)\n",
        "  print(f'Epoch {epoch+1}') \n",
        "  print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "  print(f'train_accuracy : {epoch_train_acc} val_accuracy : {epoch_val_acc}')\n",
        "  print(25*'==')\n"
      ],
      "metadata": {
        "id": "o04q2BV_RuKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "Ozqd2IslwWW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "test_h = model.init_hidden(batch_size)\n",
        "\n",
        "model.eval()\n",
        "num_tot = 0\n",
        "for inputs, labels in tqdm(test_loader):\n",
        "    test_h = tuple([each.data for each in test_h])\n",
        "\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    output, test_h = model(inputs, test_h)\n",
        "    test_loss = criterion(output.float(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    num_correct += (torch.argmax(output, 1) == torch.argmax(labels, 1)).int().sum()\n",
        "    num_tot += output.size(0)\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "test_acc = num_correct/num_tot * 100\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "id": "3QeqGkcfwSds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss_history, label='training loss')\n",
        "plt.plot(val_loss_history, label='validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-0CsOru78i3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([x.item() for x in train_acc_history], label='training acc')\n",
        "plt.plot([x.item() for x in val_acc_history], label='validation acc')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2A7_4BQ9oQWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0U89RMmkoXeW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}